ARG PYTHON_VERSION=3.9
ARG IMAGE_VARIANT=slim-bullseye
ARG JAVA_VERSION=11

FROM python:${PYTHON_VERSION}-${IMAGE_VARIANT}

# Install Java 11 (required for PySpark, compatible with PySpark 3.4.1)
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    openjdk-11-jdk \
    && rm -rf /var/lib/apt/lists/*

# Set Java environment variables
ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
ENV PATH="${JAVA_HOME}/bin:${PATH}"
ENV JAVA_OPTS="-Xmx4g -Xms2g"

ARG PYSPARK_VERSION=3.2.0

# Set working directory
WORKDIR /app

# Copy requirements file first for better Docker layer caching
COPY requirements.txt .

# Install all Python dependencies
RUN pip --no-cache-dir install -r requirements.txt

# Copy application code
COPY . .

CMD ["python", "main.py"]
