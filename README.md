# Anime Spark Project

Проект для аналізу датасету аніме з використанням Apache Spark (PySpark). Проект складається з етапів витягування даних та трансформації для отримання інсайтів про кореляцію між тегами та популярністю аніме.

## Структура проекту

```
anime-spark-project/
├── data/                              # Вхідні дані
│   └── final_animedataset.csv         # CSV файл з даними про аніме
├── transformation/                    # Модулі етапу трансформації
│   ├── __init__.py
│   ├── dataset_info.py               # Етап 1: Загальна інформація про датасет
│   ├── numeric_statistics.py         # Етап 2: Статистика числових стовпців
├── contribution/                      # Документація внесків учасників
│   └── transformation_stage/
│       └── Oskar_Oleksandr_Kobel/
│           └── CONTRIBUTION.md        # Документація роботи учасника
├── output/                            # Результати аналізу
│   └── results/                      # Згенеровані файли з результатами
│       ├── dataset_info.json
│       ├── numeric_statistics.json
│       ├── numeric_statistics.csv
├── data_extraction.py                 # Модуль витягування даних
├── main.py                            # Головний файл для запуску
├── requirements.txt                   # Залежності проекту
└── README.md                          # Цей файл
```

## Організація проекту

### Принципи архітектури

Проект організований як **модульна система**, що дозволяє кільком учасникам працювати паралельно без конфліктів:

1. **Розділення відповідальності**: Кожен модуль має чітко визначену функцію
2. **Модульність**: Кожен учасник може створити свій власний модуль аналізу
3. **Спільні утиліти**: Загальні функції винесені в окремі модулі
4. **Документація**: Кожен учасник документує свою роботу в `contribution/`

### Основні компоненти

#### 1. Модуль витягування даних (`data_extraction.py`)
- Створення схем для датасету
- Завантаження даних з CSV
- Валідація завантажених даних

#### 2. Етап трансформації (`transformation/`)

**Етап 1: Загальна інформація** (`dataset_info.py`)
- Отримання загальної інформації про датасет
- Аналіз схеми та структури
- Підрахунок null значень
- Збереження результатів у JSON

**Етап 2: Статистика числових стовпців** (`numeric_statistics.py`)
- Обчислення статистики (mean, stddev, min, max)
- Аналіз якості даних
- Оцінка розподілу значень
- Збереження результатів у JSON та CSV

#### 3. Документація внесків (`contribution/`)
Кожен учасник проекту створює свою піддиректорію з документацією:
```
contribution/
└── transformation_stage/
    └── [Ім'я_Учасника]/
        └── CONTRIBUTION.md
```

## Як запустити проект

### Вимоги
- Python 3.7+
- Apache Spark (PySpark)
- Або pandas як альтернатива (для локального тестування)

### Встановлення залежностей

```bash
pip install -r requirements.txt
```

### Запуск

```bash
python main.py
```

Програма автоматично:
1. Завантажить та валідує дані
2. Виконає етап трансформації:
   - Отримає загальну інформацію про датасет
   - Обчислить статистику числових стовпців
   - Відповість на бізнес-питання
3. Збереже всі результати у `output/results/`

## Як додати свій аналіз (для учасників команди)

### Крок 1: Створіть свій модуль аналізу

Створіть новий файл у директорії `transformation/`, наприклад:
```python
# transformation/my_analysis.py

from pyspark.sql import DataFrame
from pyspark.sql.functions import col, avg

def my_custom_analysis(df: DataFrame) -> DataFrame:
    """
    Ваш власний аналіз даних.
    
    Args:
        df: Spark DataFrame з аніме даними
    
    Returns:
        DataFrame з результатами
    """
    # Ваш код тут
    result = df.filter(col("rating") > 8.0)
    return result
```

### Крок 2: Інтегруйте у головний файл (опціонально)

Якщо хочете, щоб ваш аналіз запускався автоматично, додайте його у `main.py`:

```python
from transformation import my_analysis

# У функції main():
my_analysis.my_custom_analysis(anime_df)
```

Або запускайте окремо:
```python
from transformation import my_analysis
my_analysis.my_custom_analysis(anime_df)
```

### Крок 3: Створіть документацію

Створіть директорію та файл документації:
```
contribution/transformation_stage/Ваше_Ім'я/
└── CONTRIBUTION.md
```

У файлі опишіть:
- Що було реалізовано
- Які Spark операції використовувались
- Результати та висновки

### Приклад структури для нового учасника

```
contribution/
└── transformation_stage/
    └── Іван_Петренко/
        └── CONTRIBUTION.md
```

## Уникнення конфліктів

### Рекомендації для командної роботи:

1. **Кожен учасник працює у своєму модулі**
   - Створюйте окремі файли для вашого аналізу
   - Не змінюйте файли інших учасників без узгодження

2. **Використовуйте спільні утиліти**
   - Створюйте нові спільні функції за потреби

3. **Документуйте свою роботу**
   - Створюйте CONTRIBUTION.md у своїй директорії
   - Описуйте зміни та результати

4. **Результати зберігайте у output/results/**
   - Використовуйте унікальні імена файлів
   - Формат: `[ваше_ім'я]_[назва_аналізу].csv`

## Структура даних

### Основні колонки датасету:

- `username` - ім'я користувача
- `anime_id` - унікальний ідентифікатор аніме
- `my_score` - оцінка користувача
- `user_id` - ідентифікатор користувача
- `gender` - стать користувача
- `title` - назва аніме
- `type` - тип (TV, Movie, OVA, тощо)
- `source` - джерело (Manga, Original, тощо)
- `score` - рейтинг аніме
- `scored_by` - кількість оцінок
- `rank` - ранг аніме
- `popularity` - популярність (чим менше число, тим популярніше)
- `genre` - жанри (комою-розділені)

## Результати

Всі результати аналізу зберігаються у `output/results/`:
- JSON файли для структурованих даних
- CSV файли для табличних результатів
- Консольний вивід для швидкого перегляду

## Технічні деталі

### Використані технології:
- **Apache Spark (PySpark)** - для обробки великих даних
- **Python 3** - мова програмування
- **Pandas** - як альтернатива для локального тестування

### Spark операції:
- **Filters** - фільтрація даних за умовами
- **Aggregations** - обчислення статистики (mean, stddev, min, max, count)
- **Group By** - групування та агрегація

## Додаткова інформація

Для детальної інформації про конкретні внески учасників, дивіться файли `CONTRIBUTION.md` у відповідних директоріях.

## Контакти та підтримка

Для питань щодо структури проекту або додавання нового аналізу, звертайтесь до координатора проекту.

---

**Примітка для лекторів:** Цей проект демонструє модульну архітектуру для командної роботи з даними. Кожен учасник може працювати незалежно, створюючи свої модулі аналізу, при цьому використовуючи спільну інфраструктуру та утиліти.
