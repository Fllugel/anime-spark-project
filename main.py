try:
    from pyspark.sql import SparkSession
    SPARK_AVAILABLE = True
except ImportError:
    SPARK_AVAILABLE = False
    print("‚ö†Ô∏è  PySpark –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π –ª–æ–∫–∞–ª—å–Ω–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é pandas —è–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É")

try:
    import pandas as pd
except ImportError:
    pd = None
from data_extraction import create_anime_dataframe, validate_dataframe

# Import transformation stage modules
try:
    from transformation import dataset_info, numeric_statistics
    TRANSFORMATION_AVAILABLE = True
except ImportError:
    TRANSFORMATION_AVAILABLE = False
    print("‚ö†Ô∏è  –ú–æ–¥—É–ª—ñ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—ó –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ")

def main():
    if SPARK_AVAILABLE:
        print("üöÄ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é PySpark")
        # –°—Ç–≤–æ—Ä—ñ—Ç—å SparkSession –∑ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è–º–∏ –ø–∞–º'—è—Ç—ñ
        spark = SparkSession.builder \
            .appName("AnimeDataExtraction") \
            .config("spark.driver.memory", "4g") \
            .config("spark.driver.maxResultSize", "2g") \
            .config("spark.executor.memory", "4g") \
            .config("spark.sql.shuffle.partitions", "200") \
            .getOrCreate()

        try:
            # –ö—Ä–æ–∫ 1: –°—Ç–≤–æ—Ä—ñ—Ç—å –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ —Å—Ö–µ–º–∏ –¥–ª—è –Ω–∞–±–æ—Ä—É –¥–∞–Ω–∏—Ö
            print("–ö—Ä–æ–∫ 1: –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å—Ö–µ–º –¥–ª—è –Ω–∞–±–æ—Ä—É –¥–∞–Ω–∏—Ö")

            # –ö—Ä–æ–∫ 2: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ —Å—Ç–≤–æ—Ä–µ–Ω—ñ —Å—Ö–µ–º–∏, —Å—Ç–≤–æ—Ä—ñ—Ç—å –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ DataFrame
            print("–ö—Ä–æ–∫ 2: –°—Ç–≤–æ—Ä–µ–Ω–Ω—è DataFrame –∑ CSV —Ñ–∞–π–ª—É")
            anime_df = create_anime_dataframe(spark, "data/final_animedataset.csv")

            # –ö—Ä–æ–∫ 3: –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ —á–∏ –∫–æ—Ä–µ–∫—Ç–Ω–æ –≤—Å–µ –∑—á–∏—Ç–∞–ª–æ—Å—å
            print("–ö—Ä–æ–∫ 3: –í–∞–ª—ñ–¥–∞—Ü—ñ—è DataFrame")
            validate_dataframe(anime_df)

            print("\n‚úÖ –í—Å—ñ –∫—Ä–æ–∫–∏ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –≤–∏–∫–æ–Ω–∞–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")
            
            # –ï–¢–ê–ü –¢–†–ê–ù–°–§–û–†–ú–ê–¶–Ü–á
            if TRANSFORMATION_AVAILABLE:
                print("\n" + "="*80)
                print("–ü–û–ß–ê–¢–û–ö –ï–¢–ê–ü–£ –¢–†–ê–ù–°–§–û–†–ú–ê–¶–Ü–á")
                print("="*80)
                
                try:
                    # –ï—Ç–∞–ø 1: –ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –Ω–∞–±—ñ—Ä –¥–∞–Ω–∏—Ö
                    dataset_info.run_dataset_info_analysis(anime_df)
                    
                    # –ï—Ç–∞–ø 2: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —á–∏—Å–ª–æ–≤–∏—Ö —Å—Ç–æ–≤–ø—Ü—ñ–≤
                    numeric_statistics.run_numeric_statistics_analysis(anime_df)
                    
                    print("\n" + "="*80)
                    print("‚úÖ –ï–¢–ê–ü –¢–†–ê–ù–°–§–û–†–ú–ê–¶–Ü–á –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–Ü–®–ù–û!")
                    print("="*80)
                    
                except Exception as e:
                    print(f"\n‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—ó: {str(e)}")
                    import traceback
                    traceback.print_exc()
            else:
                print("\n‚ö†Ô∏è  –ï—Ç–∞–ø —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ–ø—É—â–µ–Ω–æ (–º–æ–¥—É–ª—ñ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ)")

        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {str(e)}")
        finally:
            spark.stop()
    else:
        print("üöÄ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é pandas (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ PySpark)")
        try:
            # –ö—Ä–æ–∫ 1: –°—Ç–≤–æ—Ä—ñ—Ç—å –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ —Å—Ö–µ–º–∏ –¥–ª—è –Ω–∞–±–æ—Ä—É –¥–∞–Ω–∏—Ö
            print("–ö—Ä–æ–∫ 1: –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å—Ö–µ–º –¥–ª—è –Ω–∞–±–æ—Ä—É –¥–∞–Ω–∏—Ö")

            # –ö—Ä–æ–∫ 2: –°—Ç–≤–æ—Ä—ñ—Ç—å DataFrame –∑ CSV —Ñ–∞–π–ª—É
            print("–ö—Ä–æ–∫ 2: –°—Ç–≤–æ—Ä–µ–Ω–Ω—è DataFrame –∑ CSV —Ñ–∞–π–ª—É")
            anime_df = create_anime_dataframe(None, "data/final_animedataset.csv")

            # –ö—Ä–æ–∫ 3: –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ —á–∏ –∫–æ—Ä–µ–∫—Ç–Ω–æ –≤—Å–µ –∑—á–∏—Ç–∞–ª–æ—Å—å
            print("–ö—Ä–æ–∫ 3: –í–∞–ª—ñ–¥–∞—Ü—ñ—è DataFrame")
            validate_dataframe(anime_df)

            print("\n‚úÖ –í—Å—ñ –∫—Ä–æ–∫–∏ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –≤–∏–∫–æ–Ω–∞–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")
            
            # –ï–¢–ê–ü –¢–†–ê–ù–°–§–û–†–ú–ê–¶–Ü–á (—Ç—ñ–ª—å–∫–∏ –¥–ª—è PySpark)
            print("\n‚ö†Ô∏è  –ï—Ç–∞–ø —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—ó –¥–æ—Å—Ç—É–ø–Ω–∏–π —Ç—ñ–ª—å–∫–∏ –∑ PySpark")

        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {str(e)}")

if __name__ == "__main__":
    main()
