"""
–ì–æ–ª–æ–≤–Ω–∏–π —Ñ–∞–π–ª –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –∑—ñ—Ä—á–∞—Å—Ç–æ—ó —Å—Ö–µ–º–∏ –¥–∞–Ω–∏—Ö —Ç–∞ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –±—ñ–∑–Ω–µ—Å-–ø–∏—Ç–∞–Ω—å.
"""

try:
    from pyspark.sql import SparkSession
    from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType
    SPARK_AVAILABLE = True
except ImportError:
    SPARK_AVAILABLE = False
    print("‚ö†Ô∏è  PySpark –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π –ª–æ–∫–∞–ª—å–Ω–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é pandas —è–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É")

from data_extraction import (
    create_star_schema,
    save_star_schema_to_parquet,
    load_star_schema_from_parquet
)


def main():
    """
    –ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –∑—ñ—Ä—á–∞—Å—Ç–æ—ó —Å—Ö–µ–º–∏ —Ç–∞ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –±—ñ–∑–Ω–µ—Å-–ø–∏—Ç–∞–Ω—å.
    """
    if SPARK_AVAILABLE:
        print("üöÄ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é PySpark")
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ SparkSession –∑ JVM –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏ –¥–ª—è Java 11/17
        spark = SparkSession.builder \
            .appName("AnimeStarSchemaAnalysis") \
            .config("spark.driver.extraJavaOptions", "--add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED") \
            .config("spark.executor.extraJavaOptions", "--add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED") \
            .config("spark.sql.legacy.timeParserPolicy", "LEGACY") \
            .config("spark.sql.parquet.datetimeRebaseModeInWrite", "LEGACY") \
            .getOrCreate()

        try:
            # –®–ª—è—Ö –¥–æ –¥–∞–Ω–∏—Ö (–ø—Ä–∞—Ü—é—î —è–∫ –ª–æ–∫–∞–ª—å–Ω–æ, —Ç–∞–∫ —ñ –≤ Docker –∑ –º–æ–Ω—Ç–æ–≤–∞–Ω–∏–º volume)
            data_path = "data"
            
            print("=" * 60)
            print("üåü –°–¢–í–û–†–ï–ù–ù–Ø –ó–Ü–†–ß–ê–°–¢–û–á –°–•–ï–ú–ò –î–ê–ù–ò–•")
            print("=" * 60)
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ –∑—ñ—Ä—á–∞—Å—Ç—É —Å—Ö–µ–º—É
            dim_user, dim_anime, dim_date, fact_ratings = create_star_schema(spark, data_path)
            
            print("\n" + "=" * 60)
            print("üìä –ü–ï–†–ï–í–Ü–†–ö–ê –°–¢–í–û–†–ï–ù–û–á –°–•–ï–ú–ò")
            print("=" * 60)
            
            # –ü–æ–∫–∞–∑—É—î–º–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤–∏–º—ñ—Ä—ñ–≤
            print("\nüìã Dim_User (–ø–µ—Ä—à—ñ 5 —Ä—è–¥–∫—ñ–≤):")
            dim_user.show(5, truncate=False)
            
            print("\nüìã Dim_Anime (–ø–µ—Ä—à—ñ 5 —Ä—è–¥–∫—ñ–≤):")
            dim_anime.show(5, truncate=False)
            
            print("\nüìã Dim_Date (–ø–µ—Ä—à—ñ 10 —Ä—è–¥–∫—ñ–≤):")
            dim_date.show(10, truncate=False)
            
            print("\nüìã Fact_UserRatings (–ø–µ—Ä—à—ñ 10 —Ä—è–¥–∫—ñ–≤):")
            fact_ratings.show(10, truncate=False)
            
            # –ü–æ–∫–∞–∑—É—î–º–æ —Å—Ö–µ–º–∏
            print("\nüìê –°—Ö–µ–º–∞ Dim_User:")
            dim_user.printSchema()
            
            print("\nüìê –°—Ö–µ–º–∞ Dim_Anime:")
            dim_anime.printSchema()
            
            print("\nüìê –°—Ö–µ–º–∞ Fact_UserRatings:")
            fact_ratings.printSchema()
            
            # –û–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ: –∑–±–µ—Ä—ñ–≥–∞—î–º–æ —É Parquet –¥–ª—è —à–≤–∏–¥—à–æ–≥–æ –¥–æ—Å—Ç—É–ø—É
            print("\n" + "=" * 60)
            print("üíæ –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø –°–•–ï–ú–ò –£ PARQUET")
            print("=" * 60)
            try:
                save_star_schema_to_parquet(
                    dim_user, dim_anime, dim_date, fact_ratings,
                    output_path=f"{data_path}/star_schema"
                )
            except Exception as e:
                print(f"‚ö†Ô∏è  –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–±–µ—Ä–µ–≥—Ç–∏ —É Parquet: {e}")
            
            print("\n" + "=" * 60)
            print("‚ùì –ë–Ü–ó–ù–ï–°-–ü–ò–¢–ê–ù–ù–Ø")
            print("=" * 60)
            print("\nüìù –¢—É—Ç –±—É–¥—É—Ç—å –¥–æ–¥–∞–≤–∞—Ç–∏—Å—è –±—ñ–∑–Ω–µ—Å-–ø–∏—Ç–∞–Ω–Ω—è –¥–æ –¥–∞–Ω–∏—Ö...")
            print("   –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ dim_user, dim_anime, dim_date, fact_ratings –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É.\n")
            
            # ============================================================
            # –¢–£–¢ –ë–£–î–£–¢–¨ –î–û–î–ê–í–ê–¢–ò–°–Ø –ë–Ü–ó–ù–ï–°-–ü–ò–¢–ê–ù–ù–Ø
            # ============================================================
            
            # –ü—Ä–∏–∫–ª–∞–¥: –ü–æ–∫–∞–∑—É—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –æ—Ü—ñ–Ω–∫–∞–º
            print("üìä –ü—Ä–∏–∫–ª–∞–¥: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ—Ü—ñ–Ω–∫–∞–º –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤")
            fact_ratings.select("User_Rating").describe().show()
            
            print("\n‚úÖ –í—Å—ñ –∫—Ä–æ–∫–∏ –≤–∏–∫–æ–Ω–∞–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")

        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {str(e)}")
            import traceback
            traceback.print_exc()
        finally:
            spark.stop()
    else:
        print("‚ùå PySpark –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π. –ë—É–¥—å –ª–∞—Å–∫–∞, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ Docker –¥–ª—è –∑–∞–ø—É—Å–∫—É.")
        print("   –ó–∞–ø—É—Å—Ç—ñ—Ç—å: docker run -v \"$(pwd)/data:/app/data\" my-spark-img")


if __name__ == "__main__":
    main()
