from data_extraction import (
    create_star_schema,
    save_star_schema_to_parquet,
    load_star_schema_from_parquet
)
from business_questions import run_artem_questions, run_bohdan_questions, run_oskar_questions # ‚¨ÖÔ∏è –û–ë–ò–î–í–Ü –§–£–ù–ö–¶–Ü–á –Ü–ú–ü–û–†–¢–û–í–ê–ù–û


def main():
    """
    –ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –∑—ñ—Ä—á–∞—Å—Ç–æ—ó —Å—Ö–µ–º–∏ —Ç–∞ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –±—ñ–∑–Ω–µ—Å-–ø–∏—Ç–∞–Ω—å.
    """
    if SPARK_AVAILABLE:
        print("üöÄ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é PySpark")
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ SparkSession –∑ JVM –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏ –¥–ª—è Java 11/17
        spark = SparkSession.builder \
            .appName("AnimeStarSchemaAnalysis") \
            .config("spark.driver.extraJavaOptions", "--add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED") \
            .config("spark.executor.extraJavaOptions", "--add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED") \
            .config("spark.sql.legacy.timeParserPolicy", "LEGACY") \
            .config("spark.sql.parquet.datetimeRebaseModeInWrite", "LEGACY") \
            .config("spark.driver.memory", "2g") \
            .config("spark.executor.memory", "2g") \
            .config("spark.sql.execution.arrow.pyspark.enabled", "false") \
            .config("spark.sql.adaptive.enabled", "true") \
            .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
            .config("spark.serializer", "org.apache.spark.serializer.KryoSerializer") \
            .config("spark.sql.execution.arrow.maxRecordsPerBatch", "1000") \
            .getOrCreate()
        
        # –ù–∞–ª–∞—à—Ç–æ–≤—É—î–º–æ —Ä—ñ–≤–µ–Ω—å –ª–æ–≥—É–≤–∞–Ω–Ω—è –¥–ª—è –ø—Ä–∏—Ö–æ–≤—É–≤–∞–Ω–Ω—è –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω—å –ø—Ä–æ Window operations
        spark.sparkContext.setLogLevel("ERROR")

        try:
            # –®–ª—è—Ö –¥–æ –¥–∞–Ω–∏—Ö (–ø—Ä–∞—Ü—é—î —è–∫ –ª–æ–∫–∞–ª—å–Ω–æ, —Ç–∞–∫ —ñ –≤ Docker –∑ –º–æ–Ω—Ç–æ–≤–∞–Ω–∏–º volume)
            data_path = "data"
            
            print("=" * 60)
            print("üåü –°–¢–í–û–†–ï–ù–ù–Ø –ó–Ü–†–ß–ê–°–¢–û–á –°–•–ï–ú–ò –î–ê–ù–ò–•")
            print("=" * 60)
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ –∑—ñ—Ä—á–∞—Å—Ç—É —Å—Ö–µ–º—É
            dim_user, dim_anime, dim_date, fact_ratings = create_star_schema(spark, data_path)
            
            print("\n" + "=" * 60)
            print("üìä –ü–ï–†–ï–í–Ü–†–ö–ê –°–¢–í–û–†–ï–ù–û–á –°–•–ï–ú–ò")
            print("=" * 60)
            
            # –ü–æ–∫–∞–∑—É—î–º–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤–∏–º—ñ—Ä—ñ–≤
            print("\nüìã Dim_User (–ø–µ—Ä—à—ñ 5 —Ä—è–¥–∫—ñ–≤):")
            dim_user.show(5, truncate=False)
            
            print("\nüìã Dim_Anime (–ø–µ—Ä—à—ñ 5 —Ä—è–¥–∫—ñ–≤):")
            dim_anime.show(5, truncate=False)
            
            print("\nüìã Dim_Date (–ø–µ—Ä—à—ñ 10 —Ä—è–¥–∫—ñ–≤):")
            dim_date.show(10, truncate=False)
            
            print("\nüìã Fact_UserRatings (–ø–µ—Ä—à—ñ 10 —Ä—è–¥–∫—ñ–≤):")
            fact_ratings.show(10, truncate=False)
            
            # –ü–æ–∫–∞–∑—É—î–º–æ —Å—Ö–µ–º–∏
            print("\nüìê –°—Ö–µ–º–∞ Dim_User:")
            dim_user.printSchema()
            
            print("\nüìê –°—Ö–µ–º–∞ Dim_Anime:")
            dim_anime.printSchema()
            
            print("\nüìê –°—Ö–µ–º–∞ Fact_UserRatings:")
            fact_ratings.printSchema()
            
            # –û–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ: –∑–±–µ—Ä—ñ–≥–∞—î–º–æ —É Parquet –¥–ª—è —à–≤–∏–¥—à–æ–≥–æ –¥–æ—Å—Ç—É–ø—É
            print("\n" + "=" * 60)
            print("üíæ –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø –°–•–ï–ú–ò –£ PARQUET")
            print("=" * 60)
            try:
                save_star_schema_to_parquet(
                    dim_user, dim_anime, dim_date, fact_ratings,
                    output_path=f"{data_path}/star_schema"
                )
            except Exception as e:
                print(f"‚ö†Ô∏è¬† –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–±–µ—Ä–µ–≥—Ç–∏ —É Parquet: {e}")
            
            print("\n" + "=" * 60)
            print("‚ùì –ë–Ü–ó–ù–ï–°-–ü–ò–¢–ê–ù–ù–Ø")
            print("=" * 60)
            
            # ============================================================
            # –ë–Ü–ó–ù–ï–°-–ü–ò–¢–ê–ù–ù–Ø –í–Ü–î –†–Ü–ó–ù–ò–• –ß–õ–ï–ù–Ü–í –ö–û–ú–ê–ù–î–ò
            # ============================================================
            
            # –ë—ñ–∑–Ω–µ—Å-–ø–∏—Ç–∞–Ω–Ω—è –≤—ñ–¥ Artem (–ê–Ω–∞–ª—ñ—Ç–∏–∫ 4)
            results_artem = run_artem_questions(
                fact_ratings, dim_user, dim_anime, dim_date,
                results_path=f"{data_path}/results"
            )
            
            # –ë—ñ–∑–Ω–µ—Å-–ø–∏—Ç–∞–Ω–Ω—è –≤—ñ–¥ Bohdan (–ê–Ω–∞–ª—ñ—Ç–∏–∫ 2) ‚¨ÖÔ∏è –î–û–î–ê–ù–û –í–ò–ö–õ–ò–ö –ë–û–ì–î–ê–ù–ê
            results_bohdan = run_bohdan_questions(
                fact_ratings, dim_user, dim_anime, dim_date,
                results_path=f"{data_path}/results"
            )

            # –ë—ñ–∑–Ω–µ—Å-–ø–∏—Ç–∞–Ω–Ω—è –≤—ñ–¥ Oskar ‚¨ÖÔ∏è –î–û–î–ê–ù–û –í–ò–ö–õ–ò–ö –û–°–ö–ê–†–ê
            results_oskar = run_oskar_questions(
                fact_ratings, dim_user, dim_anime, dim_date,
                results_path=f"{data_path}/results"
            )
            
            # ============================================================
            # –¢–£–¢ –ú–û–ñ–£–¢–¨ –î–û–î–ê–í–ê–¢–ò–°–Ø –ü–ò–¢–ê–ù–ù–Ø –í–Ü–î –Ü–ù–®–ò–• –ß–õ–ï–ù–Ü–í –ö–û–ú–ê–ù–î–ò
            # ============================================================
            # –ü—Ä–∏–∫–ª–∞–¥:
            # from business_questions import run_teammate_name_questions
            # results_teammate = run_teammate_name_questions(
            #     fact_ratings, dim_user, dim_anime, dim_date,
            #     results_path=f"{data_path}/results"
            # )
            
            print("\n‚úÖ –í—Å—ñ –∫—Ä–æ–∫–∏ –≤–∏–∫–æ–Ω–∞–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")

        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {str(e)}")
            import traceback
            traceback.print_exc()
        finally:
            spark.stop()
    else:
        print("‚ùå PySpark –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π. –ë—É–¥—å –ª–∞—Å–∫–∞, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ Docker –¥–ª—è –∑–∞–ø—É—Å–∫—É.")
        print("¬† ¬†–ó–∞–ø—É—Å—Ç—ñ—Ç—å: docker run -v \"$(pwd)/data:/app/data\" my-spark-img")


if __name__ == "__main__":
    main()