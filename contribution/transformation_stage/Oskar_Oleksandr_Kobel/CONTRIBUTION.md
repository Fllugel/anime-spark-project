# Вклад у проект: Етап трансформації

**Автор:** Oskar Oleksandr Kobel  
**Етап:** Transformation Stage

## Огляд

Цей документ описує реалізацію етапу трансформації для аналізу датасету аніме. Реалізовано модулі для отримання загальної інформації про датасет та статистичного аналізу числових стовпців.

## Що було реалізовано

### 1. Загальна інформація про набір даних

**Модуль:** `transformation/dataset_info.py`

Реалізовано функції для отримання та опису загальної інформації про датасет:
- `get_dataset_info()` - отримує базову інформацію (кількість рядків, стовпців, схему)
- `describe_dataset()` - формує детальний опис датасету
- `save_dataset_info()` - зберігає інформацію у JSON файл

**Результати зберігаються у:** `output/results/dataset_info.json`

**Що аналізується:**
- Загальна кількість рядків та стовпців
- Схема датасету (типи даних, nullable поля)
- Кількість null значень по кожному стовпцю
- Приклади даних

### 2. Статистика числових стовпців

**Модуль:** `transformation/numeric_statistics.py`

Реалізовано функції для обчислення та аналізу статистики числових стовпців:
- `get_numeric_statistics()` - обчислює базову статистику (mean, stddev, min, max, count)
- `analyze_numeric_columns()` - проводить аналіз якості даних та розподілу
- `save_numeric_statistics()` - зберігає результати у JSON та CSV

**Результати зберігаються у:**
- `output/results/numeric_statistics.json` - повна інформація
- `output/results/numeric_statistics.csv` - табличний формат

**Що аналізується:**
- Середні значення, стандартні відхилення
- Мінімальні та максимальні значення
- Коефіцієнт варіації для оцінки різноманітності даних
- Якість даних (оцінка кількості пропущених значень)
- Діапазони значень

**Числові стовпці в датасеті:**
- `anime_id` - ідентифікатор аніме
- `my_score` - оцінка користувача
- `user_id` - ідентифікатор користувача
- `scored_by` - кількість оцінок
- `rank` - ранг
- `popularity` - популярність


## Технічні деталі

### Використані Spark операції:

1. **FILTER** - для фільтрації null значень та валідації даних
2. **AGGREGATION** - для обчислення статистики (mean, stddev, min, max, count)
3. **GROUP BY** - для групування та аналізу даних по категоріях

### Обробка даних:

- Обробка null значень
- Обчислення статистичних показників для числових стовпців
- Аналіз якості даних та розподілу значень
- Коефіцієнт варіації для оцінки різноманітності даних

## Структура проекту

```
transformation/
├── __init__.py
├── dataset_info.py          # Етап 1: Загальна інформація
└── numeric_statistics.py    # Етап 2: Статистика числових стовпців
```

## Результати аналізу

Всі результати зберігаються у директорії `output/results/`:
- `dataset_info.json` - загальна інформація про датасет
- `numeric_statistics.json` - статистика числових стовпців (повна)
- `numeric_statistics.csv` - статистика числових стовпців (таблиця)

## Висновки

Реалізовано етап трансформації, який дозволяє:
1. Отримати детальну інформацію про структуру та якість датасету
2. Проаналізувати статистичні характеристики числових змінних

Всі модулі використовують потужні можливості Spark для обробки великих обсягів даних та виконання аналітичних операцій.

---

## 3. Бізнес-питання для аналізу зірчастої схеми

**Модуль:** `business_questions.py`

Реалізовано 6 бізнес-питань для аналізу зірчастої схеми даних, які демонструють різні типи аналізу та використання Spark операцій.

### Питання 1 (Filters)
**Опис:** Знайти користувачів, чия середня оцінка (`User_Mean_Score`) нижча за 6, але які при цьому подивилися (`User_Total_Completed`) більше 50 тайтлів.

**Використані операції:**
- `FILTER` - фільтрація за двома умовами
- `CAST` - приведення типів для числових порівнянь
- `ORDER BY` - сортування результатів

**Результат:** Знайдено користувачів з низькою середньою оцінкою, але високою активністю перегляду.

### Питання 2 (JOIN)
**Опис:** Вивести список аніме та оцінок, які поставив користувач 'BunnySlayer', але лише для тих аніме, де цей користувач є "критиком" (`User_Rating < 7`, оскільки шкала 0-10).

**Використані операції:**
- `JOIN` - об'єднання таблиць `Fact_UserRatings`, `Dim_User` та `Dim_Anime`
- `FILTER` - фільтрація за користувачем та умовою критичності
- `CAST` - приведення типів для порівняння

**Результат:** Список аніме та оцінок від конкретного користувача, де він виступив критиком.

### Питання 3 (GROUP BY)
**Опис:** Яка середня кількість епізодів (`AVG(Dim_Anime.Episodes)`) для аніме, згрупованих за віковим рейтингом (`Dim_Anime.Age_Rating`)?

**Використані операції:**
- `FILTER` - фільтрація валідних вікових рейтингів (виключення невалідних даних)
- `GROUP BY` - групування за віковим рейтингом
- `AVG` - обчислення середнього значення
- `CAST` - приведення типів для агрегації

**Особливості:** Додано фільтри для виключення невалідних значень (тривалість, назви студій, URL тощо).

**Результат:** Середня кількість епізодів для кожного валідного вікового рейтингу.

### Питання 4 (GROUP BY)
**Опис:** Яка середня різниця (`AVG(Fact.Rating_Deviation)`) між оцінкою користувача та середньою оцінкою аніме для кожної студії (`Dim_Anime.Studios`)?

**Використані операції:**
- `JOIN` - об'єднання `Fact_UserRatings` та `Dim_Anime`
- `FILTER` - фільтрація валідних назв студій (виключення URL та довгих рядків)
- `GROUP BY` - групування за студією
- `AVG` - обчислення середньої різниці оцінок

**Результат:** Топ 20 студій за середньою різницею оцінок (які студії отримують більш критичні або позитивні оцінки).

### Питання 5 (GROUP BY)
**Опис:** Скільки всього оцінок (`COUNT(Fact.Rating_Count)`) поставили користувачі, згруповані за статтю (`Dim_User.Gender`)?

**Використані операції:**
- `JOIN` - об'єднання `Fact_UserRatings` та `Dim_User`
- `FILTER` - виключення null значень
- `GROUP BY` - групування за статтю
- `COUNT` - підрахунок кількості оцінок

**Результат:** Розподіл кількості оцінок за гендерною ознакою користувачів.

### Питання 6 (Window Functions)
**Опис:** Розділити всіх користувачів на 5 груп (квінтилі) (`NTILE(5)`) на основі кількості переглянутих ними аніме (`Dim_User.User_Total_Completed`), щоб знайти "хардкорних" глядачів.

**Використані операції:**
- `FILTER` - виключення null значень
- `WINDOW FUNCTION` - `NTILE(5)` для розподілу на квінтилі
- `GROUP BY` - для статистики по квінтилям
- `AVG`, `SUM`, `COUNT` - агрегація для статистики

**Особливості:** 
- Використовує `NTILE()` для точного розподілу на 5 рівних груп
- Має fallback механізм з використанням `percentile_approx()` для випадків обмеження пам'яті
- Показує статистику по кожному квінтилю та топ хардкорних глядачів (квінтиль 1)

**Результат:** Розподіл користувачів на 5 квінтилів за рівнем активності перегляду.

## Технічні деталі бізнес-питань

### Використані Spark операції:

1. **FILTER** - фільтрація даних за різними умовами
2. **JOIN** - об'єднання таблиць зірчастої схеми
3. **GROUP BY** - групування для агрегації
4. **WINDOW FUNCTIONS** - `NTILE()` для розподілу на квінтилі
5. **AGGREGATION** - `AVG()`, `COUNT()`, `SUM()` для обчислення статистики
6. **CAST** - приведення типів для коректних порівнянь та обчислень

### Обробка даних:

- Приведення типів (string → double) для числових операцій
- Фільтрація невалідних даних (URL, тривалість, назви студій у вікових рейтингах)
- Оптимізація пам'яті для великих датасетів (fallback для NTILE)
- Валідація даних перед агрегацією

## Висновки

Реалізовано 6 бізнес-питань, які демонструють:
1. Використання фільтрів для виявлення специфічних паттернів у даних
2. Об'єднання таблиць зірчастої схеми для комплексного аналізу
3. Групування та агрегацію для статистичного аналізу
4. Віконні функції для сегментації та ранжування користувачів

Всі питання використовують потужні можливості Spark для ефективної обробки великих обсягів даних та виконання складних аналітичних операцій на зірчастій схемі даних.

