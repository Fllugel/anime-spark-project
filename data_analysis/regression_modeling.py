"""
–ú–æ–¥—É–ª—å –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è —Ç–∞ –æ—Ü—ñ–Ω–∫–∏ —Ä–µ–≥—Ä–µ—Å—ñ–π–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π.
"""

import os
import time
import warnings
from typing import Optional, Dict, List, Tuple, Any
import joblib

import pandas as pd
import numpy as np

from sklearn.ensemble import (
    RandomForestRegressor,
    ExtraTreesRegressor,
    BaggingRegressor,
)
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.exceptions import ConvergenceWarning

# –Ü–≥–Ω–æ—Ä—É—î–º–æ –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è –ø—Ä–æ –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü—ñ—é –¥–ª—è —á–∏—Å—Ç–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
warnings.filterwarnings("ignore", category=ConvergenceWarning)


def _load_split(
    base_path: str, split_name: str = "train", prefer_parquet: bool = True
) -> Optional[pd.DataFrame]:
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –æ–¥–∏–Ω –∑ –¥–∞—Ç–∞—Å–µ—Ç—ñ–≤ (train / validation / test).
    """
    parquet_path = os.path.join(base_path, f"{split_name}.parquet")
    csv_path = os.path.join(base_path, f"{split_name}.csv")

    if prefer_parquet and os.path.exists(parquet_path):
        return pd.read_parquet(parquet_path)
    if os.path.exists(csv_path):
        return pd.read_csv(csv_path)
    
    # Fallback for parquet if preferred but checked CSV second
    if os.path.exists(parquet_path):
        return pd.read_parquet(parquet_path)

    return None


def get_models() -> List[Tuple[str, Any]]:
    """
    –ü–æ–≤–µ—Ä—Ç–∞—î —Å–ø–∏—Å–æ–∫ –∑ –¢–û–ü-3 –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ä–µ–≥—Ä–µ—Å—ñ—ó.
    –í—ñ–¥—ñ–±—Ä–∞–Ω–æ –∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤ (–Ω–∞–π–∫—Ä–∞—â—ñ RMSE/R2).
    """
    models = [
        # 1. –ù–∞–π–∫—Ä–∞—â–∞ –º–æ–¥–µ–ª—å (RMSE ~0.448, R2 ~0.696)
        ("Random Forest (n=100)", RandomForestRegressor(
            n_estimators=100, 
            random_state=42, 
            n_jobs=-1
        )),
        
        # 2. –î—Ä—É–≥–∞ –Ω–∞–π–∫—Ä–∞—â–∞ –º–æ–¥–µ–ª—å (RMSE ~0.459, R2 ~0.680)
        ("Extra Trees", ExtraTreesRegressor(
            n_estimators=100, 
            random_state=42, 
            n_jobs=-1
        )),

        # 3. –¢—Ä–µ—Ç—è –Ω–∞–π–∫—Ä–∞—â–∞ –º–æ–¥–µ–ª—å (RMSE ~0.469, R2 ~0.666)
        ("Bagging Regressor", BaggingRegressor(
            random_state=42, 
            n_jobs=-1
        )),
    ]
    return models


def evaluate_models(
    X_train: pd.DataFrame,
    y_train: pd.Series,
    X_test: pd.DataFrame,
    y_test: pd.Series,
    models_dir: str
) -> pd.DataFrame:
    """
    –¢—Ä–µ–Ω—É—î –º–æ–¥–µ–ª—ñ (–∞–±–æ –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î —ñ—Å–Ω—É—é—á—ñ) —Ç–∞ –ø–æ–≤–µ—Ä—Ç–∞—î DataFrame –∑ –º–µ—Ç—Ä–∏–∫–∞–º–∏.
    """
    results = []
    models = get_models()
    
    os.makedirs(models_dir, exist_ok=True)

    print(f"\n–ü–æ—á–∞—Ç–æ–∫ –æ—Ü—ñ–Ω–∫–∏ {len(models)} –º–æ–¥–µ–ª–µ–π...")
    print(f"–ü–∞–ø–∫–∞ –¥–ª—è –º–æ–¥–µ–ª–µ–π: {models_dir}")
    print("-" * 90)
    print(f"{'Model Name':<30} | {'RMSE':<10} | {'MAE':<10} | {'R2':<10} | {'Time (s)':<10} | {'Status':<10}")
    print("-" * 90)

    for name, model in models:
        start_time = time.time()
        # –°—Ç–≤–æ—Ä—é—î–º–æ –±–µ–∑–ø–µ—á–Ω–µ —ñ–º'—è —Ñ–∞–π–ª—É
        safe_name = name.replace(" ", "_").replace("(", "").replace(")", "").replace("=", "_").replace(",", "")
        model_path = os.path.join(models_dir, f"{safe_name}.joblib")
        
        status = "Trained"
        
        try:
            # Check if model exists
            if os.path.exists(model_path):
                # Load model
                model = joblib.load(model_path)
                status = "Loaded"
            else:
                # Train model
                model.fit(X_train, y_train)
                # Save model
                joblib.dump(model, model_path)
            
            # Predict
            y_pred = model.predict(X_test)
            
            # Calculate metrics
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            mae = mean_absolute_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)
            
            duration = time.time() - start_time
            
            print(f"{name:<30} | {rmse:<10.4f} | {mae:<10.4f} | {r2:<10.4f} | {duration:<10.2f} | {status:<10}")
            
            results.append({
                "Model": name,
                "RMSE": rmse,
                "MAE": mae,
                "R2": r2,
                "Time": duration,
                "Status": status
            })
            
        except Exception as e:
            print(f"{name:<30} | ERROR: {str(e)}")

    print("-" * 90)
    return pd.DataFrame(results).sort_values(by="RMSE", ascending=True)


def run_regression_modeling(data_path: str = "data") -> None:
    """
    –ó–∞–ø—É—Å–∫–∞—î –ø—Ä–æ—Ü–µ—Å —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è —Ç–∞ –æ—Ü—ñ–Ω–∫–∏ —Ä–µ–≥—Ä–µ—Å—ñ–π–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π.
    """
    base_path = os.path.join(data_path, "ml_datasets", "regression")
    models_path = os.path.join(data_path, "models", "regression")
    
    print("\n" + "=" * 60)
    print("üß™ ML –†–ï–ì–†–ï–°–Ü–Ø: –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢")
    print("=" * 60)

    # 1. Load Data
    print("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö...")
    df_train = _load_split(base_path, "train")
    df_test = _load_split(base_path, "test") # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ test –¥–ª—è —Ñ—ñ–Ω–∞–ª—å–Ω–æ—ó –æ—Ü—ñ–Ω–∫–∏ –≤ —Ü—å–æ–º—É –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ
    
    if df_train is None or df_test is None:
        print("‚ùå –ü–æ–º–∏–ª–∫–∞: –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ train –∞–±–æ test –¥–∞—Ç–∞—Å–µ—Ç–∏.")
        return

    # 2. Prepare Features and Target
    target_col = "Score"
    ignore_cols = ["anime_id", "Name", "s_score", target_col]
    
    # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –∫–æ–ª–æ–Ω–∫–∏, —è–∫—ñ —î –≤ –¥–∞—Ç–∞—Å–µ—Ç—ñ
    feature_cols = [c for c in df_train.columns if c not in ignore_cols]
    
    X_train = df_train[feature_cols]
    y_train = df_train[target_col]
    
    X_test = df_test[feature_cols]
    y_test = df_test[target_col]
    
    print(f"Train shape: {X_train.shape}")
    print(f"Test shape:  {X_test.shape}")
    print(f"Features:    {len(feature_cols)}")
    
    # Handling NaNs if any (MLP and some others don't like NaNs)
    if X_train.isnull().sum().sum() > 0:
        print("‚ö†Ô∏è –£–≤–∞–≥–∞: –ó–Ω–∞–π–¥–µ–Ω–æ –ø—Ä–æ–ø—É—â–µ–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è. –ó–∞–ø–æ–≤–Ω—é—î–º–æ 0...")
        X_train = X_train.fillna(0)
        X_test = X_test.fillna(0)

    # 3. Run Evaluation
    results_df = evaluate_models(X_train, y_train, X_test, y_test, models_dir=models_path)
    
    # 4. Show Final Leaderboard
    print("\nüèÜ –¢–û–ü-3 –ú–û–î–ï–õ–ï–ô (–∑–∞ RMSE):")
    print(results_df.head(3).to_string(index=False))
    
    # 5. Save results (optional)
    results_path = os.path.join(data_path, "results", "regression_leaderboard.csv")
    os.makedirs(os.path.dirname(results_path), exist_ok=True)
    results_df.to_csv(results_path, index=False)
    print(f"\nüìÑ –ü–æ–≤–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤: {results_path}")
